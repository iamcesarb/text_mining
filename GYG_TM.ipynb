{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd \r\n",
    "import regex as re\r\n",
    "import unicodedata\r\n",
    "import spacy\r\n",
    "import nltk\r\n",
    "from nltk.probability import FreqDist\r\n",
    "import numpy as np\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "from tqdm.auto import tqdm, trange\r\n",
    "from transformers import AutoModelForSequenceClassification\r\n",
    "from transformers import TFAutoModelForSequenceClassification\r\n",
    "from transformers import AutoTokenizer, AutoConfig\r\n",
    "import numpy as np\r\n",
    "from scipy.special import softmax"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\bustossanchez.9\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nlp_en = spacy.load('en_core_web_md')\r\n",
    "nlp_es = spacy.load('es_core_news_md')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Head Count\r\n",
    "HC_columns = ['Status',\r\n",
    "                'Role',\r\n",
    "                'Agent Name' ,\r\n",
    "                'Supervisor',\t\r\n",
    "                'ACCM',\r\n",
    "                'Wave',\r\n",
    "                'LOB'\t,\r\n",
    "                'GYG_ID',\t\r\n",
    "                'SITE',\r\n",
    "                'Tenure Clasif ']\r\n",
    "\r\n",
    "HC = pd.read_excel(r'HC.xlsx', sheet_name=1, usecols=HC_columns)\r\n",
    "\r\n",
    "HC.dropna(subset=['GYG_ID'], inplace=True)\r\n",
    "HC.drop_duplicates(subset=['GYG_ID'], inplace=True)\r\n",
    "HC.to_csv('output/headcount.csv', index=False, sep=';', encoding='utf-8')\r\n",
    "#HC.columns\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "HC['GYG_ID'].values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['gyg-norma.riossaldana@teleperformance.com',\n",
       "       'gyg-katheryn.bohabotllerena@teleperformance.co',\n",
       "       'gyg-adrian.molinacabala@teleperformance.co',\n",
       "       'gyg-daniella.giraldoalvarez@teleperformance.co',\n",
       "       'gyg-cesar.guzmanvera@teleperformance.co',\n",
       "       'gyg-maria.soterocueto@teleperformance.co',\n",
       "       'gyg-vania.mejiaolivera@teleperformance.co',\n",
       "       'gyg-johana.luquepalacios@teleperformance.co',\n",
       "       'gyg-grecia.pinedorengifo@teleperformance.co',\n",
       "       'gyg-Carla.SequeirosRamos@teleperformance.co',\n",
       "       'gyg-Leonardo.AguilarLazarte@teleperformance.co',\n",
       "       'gyg-Jose.MarrouLuy@teleperformance.co',\n",
       "       'gyg-fressia.sanchezdelacruz@teleperformance.co',\n",
       "       'gyg-Pablo.AmasifuenSacsa@teleperformance.co',\n",
       "       'gyg-Carmen.CanalesOre@teleperformance.co',\n",
       "       'gyg-Sebastian.CornejoPonce@teleperformance.co',\n",
       "       'gyg-Lizbeth.GuerreroGil@teleperformance.co',\n",
       "       'gyg-Gabriel.DavilaBarraganes@teleperformance.co',\n",
       "       'gyg-Maria.RojasRengifo@teleperformance.co',\n",
       "       'gyg-Ana.HuarcayaCalderon@teleperformance.co',\n",
       "       'gyg-Andrea.DeLaTorrePerez@teleperformance.co',\n",
       "       'gyg-Cesar.DelBustoAtusparia@teleperformance.co',\n",
       "       'gyg-Vanessa.ZavaletaSandoval@teleperformance.co',\n",
       "       'gyg-Andrea.ConcepcionHerrera@teleperformance.co',\n",
       "       'gyg-Gabriel.JarrinDiaz@teleperformance.co',\n",
       "       'gyg-Anggie.RojasGuerrero@teleperformance.co',\n",
       "       'gyg-Malu.DiazAlvarez@teleperformance.co',\n",
       "       'gyg-Joaquin.JaramaMendizabal@teleperformance.co',\n",
       "       'Angelo.GuerreroLinares@teleperformance.co',\n",
       "       'Oscar.AquiseFalcon@teleperformance.co',\n",
       "       'Eduardo.RiosMenendez@teleperformance.co',\n",
       "       'Leslie.SaavedraBarnes@teleperformance.co',\n",
       "       'Alexandra.AguilarCasquero@teleperformance.co',\n",
       "       'gyg-Diego.TapiaRabanal@teleperformance.co',\n",
       "       'gyg-Kendall.CuyaPacheco@teleperformance.co',\n",
       "       'gyg-Luciana.GomezCuba@teleperformance.co',\n",
       "       'gyg-Aztreed.PiscoyaNavarro@teleperformance.co',\n",
       "       'gyg-Diego.DiazReyes@teleperformance.co',\n",
       "       'gyg-Natalia.QuevedoValverde@teleperformance.co',\n",
       "       'gyg-Diego.RodriguezFlores@teleperformance.co',\n",
       "       'gyg-Veronica.AlvaradoGuillen@teleperformance.co',\n",
       "       'gyg-Eva.EscalanteOrtiz@teleperformance.co',\n",
       "       'gyg-Gabriel.CubasLopez@teleperformance.co',\n",
       "       'gyg-Juan.EstabnCruz@teleperformance.co',\n",
       "       'gyg-Lisseth.VargasSalazar@teleperformance.co',\n",
       "       'gyg-Luis.BaltazarCalero@teleperformance.co',\n",
       "       'gyg-Aldo.LemaGaray@teleperformance.co',\n",
       "       'gyg-Brenda.LauraYovera@teleperformance.co',\n",
       "       'gyg-Diego.LlerenaMarquez@teleperformance.co',\n",
       "       'gyg-Christopher.DoroteoChampa@teleperformance.co',\n",
       "       'gyg-Oscar.Cuya@teleperformance.co',\n",
       "       'gyg-Claudia.ToribioRabines@teleperformance.co',\n",
       "       'gyg-Bruno.HernandezBarbagelatta@teleperformance.co',\n",
       "       'gyg-Manuel.EgoAguirreFunes@teleperformance.co',\n",
       "       'gyg-Daniel.VictorioManrique@teleperformance.co',\n",
       "       'gyg-Hilary.MamaniCordova@teleperformance.co',\n",
       "       'gyg-William.TorresSuarez@teleperformance.co',\n",
       "       'gyg-Darly.LizanoCaceres@teleperformance.co',\n",
       "       'gyg-Claudia.TapiaRomero@teleperformance.co',\n",
       "       'gyg-Alessandra.VargasVentura@teleperformance.co',\n",
       "       'gyg-Debora.MuhligAraya@teleperformance.co',\n",
       "       'gyg-Marco.CabreraPlasencia@teleperformance.co',\n",
       "       'gyg-Eliana.DeLaCruzMelendez@teleperformance.co',\n",
       "       'gyg-valdo.ticonagonzalez@teleperformance.co',\n",
       "       'gyg-Stephanie.NizamaMartinez@teleperformance.co',\n",
       "       'gyg-Gabriela.LauraYovera@teleperformance.co',\n",
       "       'gyg-Nayib.TantasBendezu@teleperformance.co',\n",
       "       'gyg-Carlos.HerrazAguilar@teleperformance.co',\n",
       "       'gyg-piero.ostolazaarevalo@teleperformance.co',\n",
       "       'gyg-Alejandro.PlanellsMartinez@teleperformance.co',\n",
       "       'gyg-Leidy.ValderaFrias@teleperformance.co',\n",
       "       'gyg-Sebastian.DelgadoPalacios@teleperformance.co',\n",
       "       'gyg-Victor.PozoPerez@teleperformance.co',\n",
       "       'gyg-Johan.EspinozaMoreno@teleperformance.co',\n",
       "       'gyg-Jorge.DelgadoArteaga@teleperformance.co',\n",
       "       'gyg-Adriana.OviedoOrozco@teleperformance.co',\n",
       "       'gyg-Roy.AlarconAltamirano@teleperformance.co',\n",
       "       'gyg-Sebastian.DeLaCernaMedina@teleperformance.co',\n",
       "       'gyg-cinthya.santosmoran@teleperformance.co',\n",
       "       'gyg-leslie.huamanperez@teleperformance.co',\n",
       "       'gyg-alessandra.altamiranopacheco@teleperformance.co',\n",
       "       'gyg-martha.portugalvillamizar@teleperformance.co',\n",
       "       'gyg-Wileska.ToledoCamacaro@teleperformance.co',\n",
       "       'gyg-elvis.villarrealstivala@teleperformance.co',\n",
       "       'gyg-vania.espinoleon@teleperformance.co',\n",
       "       'gyg-jose.garciamelendez@teleperformance.co',\n",
       "       'gyg-Luis.FernandezPalomino@teleperformance.co',\n",
       "       'gyg-Pedro.GalindoRojas@teleperformance.co',\n",
       "       'gyg-Jorge.PalaciosMorales@teleperformance.co',\n",
       "       'gyg-Hector.RondonRodriguez@teleperformance.co',\n",
       "       'gyg-Kiara.ToribioEspinoza@teleperformance.co',\n",
       "       'gyg-Renato.ValdiviaSolier@teleperformance.co',\n",
       "       'gyg-Valeria.VasquezMiranda@teleperformance.co',\n",
       "       'gyg-Javier.VelezmoroSanchez@teleperformance.co',\n",
       "       'gyg-Scott.VillacortaSantos@teleperformance.co',\n",
       "       'gyg-Nicole.Prudencio@teleperformance.co',\n",
       "       'gyg-Gonzalo.AlvaGamero@teleperformance.co',\n",
       "       'gyg-Pedro.Taipe@teleperformance.co',\n",
       "       'gyg-Gonzalo.MontesMoreno@teleperformance.co',\n",
       "       'gyg-Victor.LopezRengifo@teleperformance.co',\n",
       "       'gyg-Virginia.EstradaJimenez@teleperformance.co',\n",
       "       'gyg-Cesar.AlegreMatos@teleperformance.co',\n",
       "       'gyg-Santiago.LopezPuente@teleperformance.co',\n",
       "       'gyg-sammira.martinezaviles@teleperformance.co',\n",
       "       'gyg-Carlos.ChavezAguirre@teleperformance.co',\n",
       "       'gyg-Erika.OrellanaValencia@teleperformance.co',\n",
       "       'gyg-Jacob.BrennerPighi@teleperformance.co',\n",
       "       'gyg-Alicia.VasquezCastro@teleperformance.co',\n",
       "       'gyg-Brandon.ChingSanchez@teleperformance.co',\n",
       "       'gyg-Sebastian.MolinaCastillo@teleperformance.co',\n",
       "       'gyg-Melissa.TalledoValdez@teleperformance.co',\n",
       "       'gyg-Anggie.BohorquezCastro@teleperformance.co',\n",
       "       'gyg-Percy.FloresTrejo@teleperformance.co',\n",
       "       'gyg-Martha.CasasCastillo@teleperformance.co',\n",
       "       'gyg-Gustavo.GiraldoLazaro@teleperformance.co',\n",
       "       'gyg-Mathias.NoriegaAlcantara@teleperformance.co',\n",
       "       'gyg-Franco.VasquezEspinoza@teleperformance.co',\n",
       "       'gyg-Stefano.LozanoCattaneo@teleperformance.co',\n",
       "       'gyg-Angel.BuizaCabrera@teleperformance.co',\n",
       "       'gyg-Leidy.CeronLudenaDePeraza@teleperformance.co',\n",
       "       'gyg-Anthony.ZeladaCastro@teleperformance.co',\n",
       "       'gyg-Kimberly.LapaYauri@teleperformance.co',\n",
       "       'gyg-Jose.CaceresDelgado@teleperformance.co',\n",
       "       'gyg-Luis.AriasOnofre@teleperformance.co',\n",
       "       'gyg-Jimena.HinostrozaPio@teleperformance.co',\n",
       "       'gyg-Alondra.ChamochumbiVicuna@teleperformance.co',\n",
       "       'gyg-Andrea.PaucarmaytaLoaiza@teleperformance.co',\n",
       "       'gyg-Alejandra.PalominoHerrera@teleperformance.co',\n",
       "       'gyg-Mauro.DeSouzaFerreyraArriaga@teleperformance.co',\n",
       "       'gyg-Esteban.PereaLongaray@teleperformance.co',\n",
       "       'gyg-Renato.MejiaSanmiguel@teleperformance.co',\n",
       "       'gyg-Aaron.GonzalesTorres@teleperformance.co',\n",
       "       'gyg-Alvaro.HinojosaRoessl@teleperformance.co',\n",
       "       'gyg-Alexandra.LaderaMejia@teleperformance.co',\n",
       "       'gyg-Maria.ArceMatias@teleperformance.co',\n",
       "       'gyg-Carla.PintoBurgos@teleperformance.co',\n",
       "       'gyg-Solange.RinconSoto@teleperformance.co',\n",
       "       'gyg-Benjamin.TalavaneroBulnes@teleperformance.co',\n",
       "       'gyg-Stephanie.DiazPalomino@teleperformance.co',\n",
       "       'gyg-Sandy.TarrilloFernandez@teleperformance.co',\n",
       "       'gyg-Viviana.TamaraTamara@teleperformance.co',\n",
       "       'gyg-Nicolas.RuizDeCastillaHuby@teleperformance.co',\n",
       "       'gyg-Milagros.AlmeidaMesias@teleperformance.co',\n",
       "       'gyg-Eddington.RomanArismendis@teleperformance.co',\n",
       "       'gyg-Leidy.RojasMedrano@teleperformance.co',\n",
       "       'gyg-Silvia.SilveraRocca@teleperformance.co',\n",
       "       'gyg-Manuel.GarciaLeandro@teleperformance.co',\n",
       "       'gyg-Isabeau.GabrielGutierrez@teleperformance.co',\n",
       "       'gyg-Diana.AlvaGonzalez@teleperformance.co',\n",
       "       'gyg-Debbie.CentenoAguirre@teleperformance.co',\n",
       "       'gyg-Xiomara.HerreraIparraguirre@teleperformance.co',\n",
       "       'gyg-Renzo.ClavoTamayo@teleperformance.co',\n",
       "       'gyg-Gretta.VelasquezEscobedo@teleperformance.co',\n",
       "       'gyg-Andrea.DeLaCruzMartinez@teleperformance.co',\n",
       "       'gyg-Maria.SalazarAliaga@teleperformance.co',\n",
       "       'gyg-Angelo.ParicelaPrincipe@teleperformance.co',\n",
       "       'gyg-Lucia.AtuncarTorres@teleperformance.co',\n",
       "       'gyg-Gianella.GamarraZevallo@teleperformance.co',\n",
       "       'gyg-Maria.SilvaRodriguez@teleperformance.co',\n",
       "       'gyg-Grecia.PeraltaRequejo@teleperformance.co',\n",
       "       'gyg-Sebastian.PancorboQuispe@teleperformance.co',\n",
       "       'gyg-Leonardo.CastilloAcon@teleperformance.co',\n",
       "       'gyg-Brissa.GabrielliYupanqui@teleperformance.co',\n",
       "       'gyg-flavio.vasquezdelacruz@teleperformance.co',\n",
       "       'gyg-Andy.MinamoSimon@teleperformance.co',\n",
       "       'gyg-Jose.UribeMoreno@teleperformance.co',\n",
       "       'gyg-diego.paredesancaya@teleperformance.co',\n",
       "       'gyg-Carlos.PortillaAlvarez@teleperformance.co',\n",
       "       'gyg-milagros.retamozocalla@teleperformance.co',\n",
       "       'gyg-carol.calixtobao@teleperformance.co\\n',\n",
       "       'gyg-Joseph.RiveroSanchez@teleperformance.co',\n",
       "       'gyg-omar.llanosespinoza@teleperformance.co',\n",
       "       'gyg-Patricia.FernandezBorjas@teleperformance.co',\n",
       "       'gyg-Maria.GomezBadoino@teleperformance.co',\n",
       "       'gyg-Michelle.PineroMartinez@teleperformance.co',\n",
       "       'gyg-Mariafe.FernandezNeyra@teleperformance.co',\n",
       "       'gyg-Mariana.AguilarGarrido@teleperformance.co',\n",
       "       'gyg-Joan.SeguraPena@teleperformance.co',\n",
       "       'gyg-Ronald.CaballeroMazuelos@teleperformance.co',\n",
       "       'gyg-Louanna.HerreraSalino@teleperformance.co',\n",
       "       'gyg-julio.ruizortiz@teleperformance.co',\n",
       "       'gyg-Jose.PaitanAlejos@teleperformance.co',\n",
       "       'gyg-Gabriela.GarciaSantacruz@teleperformance.co',\n",
       "       'gyg-Valeria.BardalesVilchez@teleperformance.co',\n",
       "       'gyg-jesus.sanchezmieres@teleperformance.co',\n",
       "       'gyg-Gabriela.QuillamaSolis@teleperformance.co',\n",
       "       'gyg-luis.guzmanreyes@teleperformance.co',\n",
       "       'gyg-Marialaura.BobadillaAguilar@teleperformance.co',\n",
       "       'gyg-Andrea.TorresParedes@teleperformance.co',\n",
       "       'gyg-Ariana.MiyauchiCanepa@teleperformance.co',\n",
       "       'gyg-Andre.MendozaArce@teleperformance.co',\n",
       "       'gyg-Miguel.AcostaCordova@teleperformance.co',\n",
       "       'gyg-Alvaro.FloresUribe@teleperformance.co',\n",
       "       'gyg-Andre.LopezSenitagoya@teleperformance.co',\n",
       "       'gyg-Teresa.VillafanVillafan@teleperformance.co',\n",
       "       'gyg-yenisey.landriansilvera@teleperformance.co',\n",
       "       'gyg-Jose.HidalgoOrbe@teleperformance.co',\n",
       "       'gyg-Marissa.TumialanCalvay@teleperformance.co',\n",
       "       'gyg-Daniel.FloresCasto@teleperformance.co',\n",
       "       'gyg-daniela.alvaradopalomino@teleperformance.co',\n",
       "       'gyg-Maria.TiradoCigaran@teleperformance.co',\n",
       "       'gyg-Claudia.ZenitagoyaHernandez@teleperformance.co',\n",
       "       'gyg-Gina.BabilonBabilon@teleperformance.co',\n",
       "       'gyg-Gabriel.SantaMaria@teleperformance.co',\n",
       "       'gyg-Leonardo.RiosObando@teleperformance.co',\n",
       "       'gyg-Denny.CarrizoRivera@teleperformance.co',\n",
       "       'gyg-Nelissa.ValverdeCaldas@teleperformance.co',\n",
       "       'gyg-Joel.RomeroPonceDeLeon@teleperformance.co',\n",
       "       'gyg-fernando.vergaramalca@teleperformance.co',\n",
       "       'gyg-Rosa.MartinezCastellanos@teleperformance.co',\n",
       "       'gyg-Alberto.GavanchoTello@teleperformance.co',\n",
       "       'gyg-Sebastian.BianchiVasquez@teleperformance.co',\n",
       "       'gyg-Gabriela.CaballeroCarbajal@teleperformance.co',\n",
       "       'gyg-Efrain.GuevaraSanchez@teleperformance.co',\n",
       "       'gyg-david.cordovaregalado@teleperformance.co',\n",
       "       'gyg-Gary.MurgaFlores@teleperformance.co',\n",
       "       'gyg-Ghyslane.VargasPacheco@teleperformance.co',\n",
       "       'gyg-Amanda.LucanoAndia@teleperformance.co',\n",
       "       'gyg-Valeria.SaavedraRodriguez@teleperformance.co',\n",
       "       'gyg-Alejandro.PortalesPaypay@teleperformance.co',\n",
       "       'gyg-Pietro.PighiBel@teleperformance.co',\n",
       "       'gyg-Viviana.PaccoMarcos@teleperformance.co',\n",
       "       'Marisol.YarlequeVeliz@teleperformance.co',\n",
       "       'gyg-renzo.alfaroaraujo@teleperformance.co',\n",
       "       'gyg-Joan.HernandezHuaman@teleperformance.co',\n",
       "       'gyg-gabriel.manriqueprada@teleperformance.co',\n",
       "       'gyg-Mikjail.GarbozaSiabala@teleperformance.co',\n",
       "       'gyg-Angie.TejadaOsco@teleperformance.co',\n",
       "       'gyg-Raul.MejiaRomero@teleperformance.co',\n",
       "       'gyg-karla.chungvelasquez@teleperformance.co',\n",
       "       'gyg-Dayana.PoquiomaValentin@teleperformance.co',\n",
       "       'gyg-snider.ochoadelgado@teleperformance.co',\n",
       "       'gyg-grecia.romanneyra@teleperformance.co',\n",
       "       'gyg-oscar.carbajalpretto@teleperformance.co',\n",
       "       'gyg-Ariana.ZavalaMendez@teleperformance.co',\n",
       "       'gyg-Mikaela.FalconYalico@teleperformance.co',\n",
       "       'gyg-Lia.RosadoHerrera@teleperformance.co',\n",
       "       'gyg-Ethel.PiscoyaRomero@teleperformance.co',\n",
       "       'gyg-Sebastian.LojasDioses@teleperformance.co',\n",
       "       'gyg-Karoline.LlaqueAsurza@teleperformance.co',\n",
       "       'gyg-Karol.SalasLinan@teleperformance.co',\n",
       "       'gyg-Helen.PickmanMartinez@teleperformance.co',\n",
       "       'gyg-Joanna.GradosEstrada@teleperformance.co',\n",
       "       'gyg-Francesco.GuaniloBerdejo@teleperformance.co',\n",
       "       'gyg-Stephany.ParhuanaVenegas@teleperformance.co',\n",
       "       'gyg-Solange.PachecoEscobedo@teleperformance.co',\n",
       "       'gyg-jhonny.zegarraumbo@teleperformance.co',\n",
       "       'gyg-Piero.CipraRicapa@teleperformance.co',\n",
       "       'gyg-Fabiana.ZegarraBallonCabrera@teleperformance.co',\n",
       "       'gyg-Maria.VargasCanitrot@teleperformance.co',\n",
       "       'gyg-Jose.CustodioMoreno@teleperformance.co',\n",
       "       'gyg-Gianella.HilserMuro@teleperformance.co',\n",
       "       '\\ngyg-Melissa.ChoquehuancaCano@teleperformance.co',\n",
       "       'gyg-Leonardo.MartinezBravo@teleperformance.co',\n",
       "       'gyg-Renzo.MelendezGonzales@teleperformance.co',\n",
       "       'gyg-Johan.GonzalesDavila@teleperformance.co',\n",
       "       'gyg-Vanessa.SalinasSosa@teleperformance.co',\n",
       "       'gyg-Tatiana.ZamudioHuamani@teleperformance.co',\n",
       "       'gyg-Santiago.LiviaMoncada@teleperformance.co',\n",
       "       'gyg-Diego.MendozaJulca@teleperformance.co',\n",
       "       'gyg-Jose.NavarroDelgado@teleperformance.co',\n",
       "       'gyg-Anthony.ChucosVilches@teleperformance.co'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "HC[HC['GYG_ID'].duplicated()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>Role</th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>ACCM</th>\n",
       "      <th>Wave</th>\n",
       "      <th>LOB</th>\n",
       "      <th>GYG_ID</th>\n",
       "      <th>SITE</th>\n",
       "      <th>Tenure Clasif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Status, Role, Agent Name, Supervisor, ACCM, Wave, LOB, GYG_ID, SITE, Tenure Clasif ]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "columns=[   'Agents Email',\r\n",
    "            'Freshdesk Ticket ID',\r\n",
    "            'Date',\r\n",
    "            'Freshdesk Ticket Source',\r\n",
    "            'CSAT CSAT Rating Main Question',\r\n",
    "            'CSAT Csat Feedback',\r\n",
    "            'Freshdesk Ticket Language',\r\n",
    "            'Contact Reason 1st  Requester',\r\n",
    "            'Contact Reason 1st Intent',\r\n",
    "            'Contact Reason 1st Theme',\r\n",
    "            'Freshdesk Group Name',\r\n",
    "            'CSAT Score']\r\n",
    "\r\n",
    "\r\n",
    "import os \r\n",
    "\r\n",
    "filename=os.listdir('input')[0]\r\n",
    "path = os.path.join('input', filename)\r\n",
    "\r\n",
    "data = pd.read_excel(path, usecols=columns)\r\n",
    "\r\n",
    "\r\n",
    "rename_columns= {'Agents Email' : 'Agent Email',\r\n",
    "            'Freshdesk Ticket ID':'Survey ID',\r\n",
    "            'Freshdesk Ticket Source':'Channel',\r\n",
    "            'CSAT CSAT Rating Main Question': 'CSAT Score',\r\n",
    "            'CSAT Csat Feedback':'Feedback',\r\n",
    "            'Freshdesk Ticket Language':'Language',\r\n",
    "            'Contact Reason 1st  Requester':'Requester',\r\n",
    "            'Contact Reason 1st Intent':'Intent',\r\n",
    "            'Contact Reason 1st Theme':'Theme',\r\n",
    "            'Freshdesk Group Name':'Freshdesk Group',\r\n",
    "            'CSAT Score':'% CSAT'}\r\n",
    "\r\n",
    "\r\n",
    "            \r\n",
    "data.rename(columns=rename_columns, inplace=True)\r\n",
    "\r\n",
    "data['Feedback'] = data['Feedback'].replace('\"\"','')\r\n",
    "data.mask(data=='',inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_NPS(x):\r\n",
    "    if (x > 0):\r\n",
    "        return \"Promoter\"\r\n",
    "    elif (x == 0):\r\n",
    "        return \"Passive\"\r\n",
    "    else:\r\n",
    "        return \"Detractor\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "before_preprocessing = len(data)\r\n",
    "print('Data len before preprocessing', before_preprocessing)\r\n",
    "\r\n",
    "data.dropna(subset=['CSAT Score'], inplace=True)\r\n",
    "print('After removing NaN CSAT Score', len(data))\r\n",
    "\r\n",
    "data['CSAT'] = data['CSAT Score'].apply(lambda x: get_NPS(x))\r\n",
    "data.drop(['CSAT Score'], axis = 1, inplace = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data len before preprocessing 39404\n",
      "After removing NaN CSAT Score 39404\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Agent Email            0\n",
       "Survey ID              0\n",
       "Date                   0\n",
       "Channel                0\n",
       "Feedback           33892\n",
       "Language               0\n",
       "Requester            968\n",
       "Intent              1097\n",
       "Theme               1097\n",
       "Freshdesk Group        0\n",
       "% CSAT                 0\n",
       "CSAT                   0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "data.dropna(subset=['Survey ID'], inplace=True)\r\n",
    "data['Survey ID']=data['Survey ID'].astype(str)+data['Agent Email'].astype(str)+data['Date'].astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Agent Email', 'Survey ID', 'Date', 'Channel', 'Feedback', 'Language',\n",
       "       'Requester', 'Intent', 'Theme', 'Freshdesk Group', '% CSAT', 'CSAT'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('Data len before preprocessing', before_preprocessing)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "data.drop_duplicates(subset='Survey ID', inplace=True)\r\n",
    "print('After removing SurveyID duplicates', len(data))\r\n",
    "\r\n",
    "data = data[data['Agent Email']!='Merged']\r\n",
    "print('After removing \\'Merged\\' data', len(data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data len before preprocessing 39404\n",
      "After removing SurveyID duplicates 38600\n",
      "After removing 'Merged' data 38530\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data.isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Agent Email            0\n",
       "Survey ID              0\n",
       "Date                   0\n",
       "Channel                0\n",
       "Feedback           33148\n",
       "Language               0\n",
       "Requester            624\n",
       "Intent               687\n",
       "Theme                687\n",
       "Freshdesk Group        0\n",
       "% CSAT                 0\n",
       "CSAT                   0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Agent Email                object\n",
       "Survey ID                  object\n",
       "Date               datetime64[ns]\n",
       "Channel                    object\n",
       "Feedback                   object\n",
       "Language                   object\n",
       "Requester                  object\n",
       "Intent                     object\n",
       "Theme                      object\n",
       "Freshdesk Group            object\n",
       "% CSAT                      int64\n",
       "CSAT                       object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "data.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Agent Email                object\n",
       "Survey ID                  object\n",
       "Date               datetime64[ns]\n",
       "Channel                    object\n",
       "Feedback                   object\n",
       "Language                   object\n",
       "Requester                  object\n",
       "Intent                     object\n",
       "Theme                      object\n",
       "Freshdesk Group            object\n",
       "% CSAT                      int64\n",
       "CSAT                       object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#surveys_raw = pd.read_csv('output/surveys_raw.csv', sep=';')\r\n",
    "\r\n",
    "#surveys_raw = pd.read_excel('output/surveys_raw_backup.xlsx')\r\n",
    "\r\n",
    "#surveys_raw.to_excel('output/surveys_raw_backup.xlsx', index=False)\r\n",
    "\r\n",
    "#data=pd.concat([surveys_raw,data])\r\n",
    "\r\n",
    "data[ \"Date\" ]=pd.to_datetime(data[ 'Date' ])\r\n",
    "\r\n",
    "# Data since 01/01/2023\r\n",
    "data.drop_duplicates(subset='Survey ID', keep='last', inplace=True)\r\n",
    "data.to_csv('output/surveys_raw.csv', index=False, sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Constuct the Data Frame with only SURVEY ID key \r\n",
    "\r\n",
    "df = data[['Survey ID', 'Feedback','Language']]\r\n",
    "\r\n",
    "#Use only data with Comments\r\n",
    "df = df[df['Feedback'].notnull()]\r\n",
    "df['Feedback'] = df['Feedback'].apply(str)\r\n",
    "df['Feedback'] = df['Feedback'].replace('\"\"','')\r\n",
    "df['Feedback'] = df['Feedback'].apply(lambda x: x.replace('\"',''))\r\n",
    "df.head()\r\n",
    "df_sentiment = df.copy()\r\n",
    "\r\n",
    "#df_sentiment.to_excel('sentiment_raw.xlsx', index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df['Feedback']=df['Feedback'].apply(lambda x: str(x).lower())\r\n",
    "\r\n",
    "#Remove special characters\r\n",
    "\r\n",
    "special_chars1 = df['Feedback'].apply(lambda x: [each for each in list(x) if not each.isalnum() and each != ' '] if type(x) == type('Hello') else '')\r\n",
    "flat_list1 = [item for sublist in special_chars1 for item in sublist]\r\n",
    "print(set(flat_list1)) # Set = List of character with no repeat\r\n",
    "special_char_to_remove = set(flat_list1)\r\n",
    "\r\n",
    "def remove_special_char(words):\r\n",
    "    return [word for word in words if not str(word) in special_char_to_remove]\r\n",
    "\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'“', '(', '$', ',', ']', '_', '*', '’', ')', '\\\\', '❤', '\\u200d', ';', '€', '#', \"'\", '‘', '&', '[', '¡', '\\xa0', '«', '|', '⭐', '/', '+', '£', '„', '✨', '>', '☺', '!', '…', '！', '♡', '@', '–', '-', ':', '♥', '¿', '️', '•', '✌', '♀', '。', '☹', '”', '、', '~', '<', '=', '%', '`', '.', '»', '\\u3000', '—', '´', '?'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>i got help from valeria vasquez (amoung others...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12990999gyg-fressia.sanchezdelacruz@teleperfor...</td>\n",
       "      <td>everything was great!</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13002836gyg-karla.chungvelasquez@teleperforman...</td>\n",
       "      <td>don’t understand how you can charge someone tw...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13016161gyg-cinthya.santosmoran@teleperformanc...</td>\n",
       "      <td>issue an invoice with vat id</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13014113gyg-cinthya.santosmoran@teleperformanc...</td>\n",
       "      <td>asking how to download barcode for swiss pass,...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39381</th>\n",
       "      <td>17135621gyg-renato.valdiviasolier@teleperforma...</td>\n",
       "      <td>la primera vez que me comunique con ustedes fu...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39383</th>\n",
       "      <td>17616079gyg-alessandra.altamiranopacheco@telep...</td>\n",
       "      <td>nothing the person was excellent in all criteria</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39393</th>\n",
       "      <td>17627457gyg-alondra.chamochumbivicuna@teleperf...</td>\n",
       "      <td>seriously the best customer service i have exp...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>17592259angelo.guerrerolinares@teleperformance...</td>\n",
       "      <td>very helpful and friendly indeed! thanks!</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39402</th>\n",
       "      <td>17618394gyg-javier.velezmorosanchez@teleperfor...</td>\n",
       "      <td>todo perfecto y solucionado rapidamente</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Survey ID  \\\n",
       "6      12963500gyg-valeria.vasquezmiranda@teleperform...   \n",
       "13     12990999gyg-fressia.sanchezdelacruz@teleperfor...   \n",
       "18     13002836gyg-karla.chungvelasquez@teleperforman...   \n",
       "19     13016161gyg-cinthya.santosmoran@teleperformanc...   \n",
       "25     13014113gyg-cinthya.santosmoran@teleperformanc...   \n",
       "...                                                  ...   \n",
       "39381  17135621gyg-renato.valdiviasolier@teleperforma...   \n",
       "39383  17616079gyg-alessandra.altamiranopacheco@telep...   \n",
       "39393  17627457gyg-alondra.chamochumbivicuna@teleperf...   \n",
       "39396  17592259angelo.guerrerolinares@teleperformance...   \n",
       "39402  17618394gyg-javier.velezmorosanchez@teleperfor...   \n",
       "\n",
       "                                                Feedback Language  \n",
       "6      i got help from valeria vasquez (amoung others...  English  \n",
       "13                                 everything was great!  English  \n",
       "18     don’t understand how you can charge someone tw...  English  \n",
       "19                          issue an invoice with vat id  English  \n",
       "25     asking how to download barcode for swiss pass,...  English  \n",
       "...                                                  ...      ...  \n",
       "39381  la primera vez que me comunique con ustedes fu...  Spanish  \n",
       "39383   nothing the person was excellent in all criteria  English  \n",
       "39393  seriously the best customer service i have exp...  English  \n",
       "39396          very helpful and friendly indeed! thanks!  English  \n",
       "39402            todo perfecto y solucionado rapidamente  Spanish  \n",
       "\n",
       "[5382 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "##  No se le pueden quitar las tildes porque si no el npl_es no lematiza \r\n",
    "\r\n",
    "\r\n",
    "df['Feedback']=df['Feedback'].apply(lambda x: str(x).lower())\r\n",
    "\r\n",
    "#Remove special characters\r\n",
    "\r\n",
    "special_chars1 = df['Feedback'].apply(lambda x: [each for each in list(x) if not each.isalnum() and each != ' '] if type(x) == type('Hello') else '')\r\n",
    "flat_list1 = [item for sublist in special_chars1 for item in sublist]\r\n",
    "print(set(flat_list1)) # Set = List of character with no repeat\r\n",
    "special_char_to_remove = set(flat_list1)\r\n",
    "\r\n",
    "def remove_special_char(words):\r\n",
    "    return [word for word in words if not str(word) in special_char_to_remove]\r\n",
    "\r\n",
    "df['spacy']=df['Feedback'].apply(lambda x: remove_special_char(nlp_es(str(x)))).where(df['Language'] == 'Spanish')\r\n",
    "df['spacy']=df['Feedback'].apply(lambda x: remove_special_char(nlp_en(str(x)))).where(df['Language'] == 'English', other = df['spacy'])\r\n",
    "\r\n",
    "df.dropna(inplace=True, subset=['spacy'])\r\n",
    "\r\n",
    "df['Lemmatization'] = df['spacy'].apply(lambda doc: [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token) > 2 and token.is_alpha]) # doc if str(doc) == 'nan' else # not token.is_stop and\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df_cat = df.copy()\r\n",
    "\r\n",
    "df_cat['joint_lemma_words'] = df_cat['Lemmatization'].apply(lambda x: ' '.join(x))\r\n",
    "df_cat.drop(['Lemmatization', 'Feedback', 'Language','spacy'], axis = 1, inplace = True)\r\n",
    "\r\n",
    "\r\n",
    "df_cat.to_excel('categorization_test.xlsx', index=False)\r\n",
    "\r\n",
    "df.to_csv(\"output/freqwords.csv\",index=False, sep=';', encoding='utf-8')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'“', '(', '$', ',', ']', '_', '*', '’', ')', '\\\\', '❤', '\\u200d', ';', '€', '#', \"'\", '‘', '&', '[', '¡', '\\xa0', '«', '|', '⭐', '/', '+', '£', '„', '✨', '>', '☺', '!', '…', '！', '♡', '@', '–', '-', ':', '♥', '¿', '️', '•', '✌', '♀', '。', '☹', '”', '、', '~', '<', '=', '%', '`', '.', '»', '\\u3000', '—', '´', '?'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Drop 'Feedback' and 'spacy' columns\r\n",
    "df.drop(['Feedback', 'spacy', 'Language'], axis=1, inplace=True)\r\n",
    "\r\n",
    "#Super Important! \r\n",
    "df.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "df_bigram=df.copy()\r\n",
    "df_trigram=df.copy()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Common words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "df[\"frecwords\"]=df['Lemmatization'].apply(lambda x: FreqDist(x))\r\n",
    "df=df.drop(['Lemmatization'], axis = 1)\r\n",
    "\r\n",
    "df_temp = pd.DataFrame(pd.DataFrame(df[\"frecwords\"].values.tolist()).stack().reset_index(level=1))\r\n",
    "df_temp.columns = ['Words', 'Frequency']\r\n",
    "df= df.join(df_temp)\r\n",
    "\r\n",
    "df.drop([\"frecwords\"], axis = 1, inplace = True)\r\n",
    "\r\n",
    "# Removing unnecesary blankspaces around words\r\n",
    "df['Words'] = df['Words'].apply(lambda x: str(x).strip())\r\n",
    "\r\n",
    "df.dropna(inplace=True)\r\n",
    "df['Frequency'] = df['Frequency'].astype('int8')\r\n",
    "df.to_csv(r\"output/Words.csv\", encoding = 'utf-8', index = False, sep=';')\r\n",
    "\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Words</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>get</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>help</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>valeria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>amoung</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID    Words  Frequency\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...      get          1\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...     help          1\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...  valeria          1\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...  vasquez          1\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...   amoung          1"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigrams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def common_bigrams(words_list):\r\n",
    "    list_bigrams = list(nltk.bigrams(words_list))\r\n",
    "    filtered_bigram_dist = FreqDist(list_bigrams)\r\n",
    "    return dict(filtered_bigram_dist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "\r\n",
    "df_bigram['bigrams_dict'] = df_bigram['Lemmatization'].apply(lambda x: common_bigrams(x))\r\n",
    "\r\n",
    "# Melt frequency distribution dictionary\r\n",
    "# https://stackoverflow.com/questions/61354434/melt-pandas-dataframe-containing-column-of-dictionaries-such-that-the-dictionary\r\n",
    "df_temp_bigrams = pd.DataFrame(pd.DataFrame(df_bigram['bigrams_dict'].values.tolist()).stack().reset_index(level=1))\r\n",
    "df_temp_bigrams.columns = ['Bigrams_tuple', 'bigrams_count']\r\n",
    "\r\n",
    "display(df_temp_bigrams)\r\n",
    "# Split bigram tuple in columns\r\n",
    "# https://stackoverflow.com/questions/29550414/how-can-i-split-a-column-of-tuples-in-a-pandas-dataframe\r\n",
    "df_temp_bigrams[['bigram_1', 'bigram_2']] = pd.DataFrame(df_temp_bigrams['Bigrams_tuple'].tolist(), index=df_temp_bigrams.index)\r\n",
    "\r\n",
    "df_bigram = df_bigram.join(df_temp_bigrams)\r\n",
    "\r\n",
    "df_bigram.drop(['Lemmatization', 'bigrams_dict','Bigrams_tuple' ], axis = 1, inplace = True)\r\n",
    "df_bigram['Bigrams'] = df_bigram['bigram_1'] +\" \" +df_bigram['bigram_2']\r\n",
    "df_bigram.dropna(subset=['bigrams_count'], inplace=True)\r\n",
    "df_bigram['bigrams_count'] = df_bigram['bigrams_count'].astype('int8')\r\n",
    "df_bigram.to_csv(\"output/Bigrams.csv\",index=False, sep=';', encoding='utf-8')\r\n",
    "df_bigram.head()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrams_tuple</th>\n",
       "      <th>bigrams_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(get, help)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(help, valeria)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(valeria, vasquez)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(vasquez, amoung)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(amoung, fast)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>(seriously, good)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>(helpful, friendly)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>(friendly, thank)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>(perfecto, solucionado)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>(solucionado, rapidamente)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Bigrams_tuple  bigrams_count\n",
       "0                    (get, help)            1.0\n",
       "0                (help, valeria)            1.0\n",
       "0             (valeria, vasquez)            1.0\n",
       "0              (vasquez, amoung)            1.0\n",
       "0                 (amoung, fast)            1.0\n",
       "...                          ...            ...\n",
       "5300           (seriously, good)            1.0\n",
       "5301         (helpful, friendly)            1.0\n",
       "5301           (friendly, thank)            1.0\n",
       "5302     (perfecto, solucionado)            1.0\n",
       "5302  (solucionado, rapidamente)            1.0\n",
       "\n",
       "[43520 rows x 2 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>bigrams_count</th>\n",
       "      <th>bigram_1</th>\n",
       "      <th>bigram_2</th>\n",
       "      <th>Bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>get</td>\n",
       "      <td>help</td>\n",
       "      <td>get help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>help</td>\n",
       "      <td>valeria</td>\n",
       "      <td>help valeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>valeria</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>valeria vasquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>amoung</td>\n",
       "      <td>vasquez amoung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>amoung</td>\n",
       "      <td>fast</td>\n",
       "      <td>amoung fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID  bigrams_count bigram_1  \\\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...              1      get   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...              1     help   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...              1  valeria   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...              1  vasquez   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...              1   amoung   \n",
       "\n",
       "  bigram_2          Bigrams  \n",
       "0     help         get help  \n",
       "0  valeria     help valeria  \n",
       "0  vasquez  valeria vasquez  \n",
       "0   amoung   vasquez amoung  \n",
       "0     fast      amoung fast  "
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trigrams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def common_trigrams(words_list):\r\n",
    "    list_trigrams = list(nltk.trigrams(words_list))\r\n",
    "    filtered_trigrams_dist = FreqDist(list_trigrams)\r\n",
    "    return dict(filtered_trigrams_dist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df_trigram_backup=df_trigram"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df_trigram = df_trigram_backup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\r\n",
    "df_trigram['trigrams_dict'] = df_trigram['Lemmatization'].apply(lambda x: common_trigrams(x))\r\n",
    "\r\n",
    "# Melt frequency distribution dictionary\r\n",
    "# https://stackoverflow.com/questions/61354434/melt-pandas-dataframe-containing-column-of-dictionaries-such-that-the-dictionary\r\n",
    "df_temp_trigrams = pd.DataFrame(pd.DataFrame(df_trigram['trigrams_dict'].values.tolist()).stack().reset_index(level=1))\r\n",
    "df_temp_trigrams.columns = ['Trigrams_tuple', 'Trigrams_count']\r\n",
    "\r\n",
    "display(df_temp_trigrams)\r\n",
    "\r\n",
    "df_temp_trigrams[['trigram_1', 'trigram_2', 'trigram_3']] = pd.DataFrame(df_temp_trigrams['Trigrams_tuple'].tolist(), index=df_temp_trigrams.index)\r\n",
    "\r\n",
    "df_trigram = df_trigram.join(df_temp_trigrams)\r\n",
    "\r\n",
    "df_trigram.drop(['Lemmatization', 'trigrams_dict','Trigrams_tuple' ], axis = 1, inplace = True)\r\n",
    "df_trigram['Trigrams'] = df_trigram['trigram_1'] +\" \" +df_trigram['trigram_2'] +\" \" +df_trigram['trigram_3']\r\n",
    "df_trigram.dropna(subset=['Trigrams_count'], inplace=True)\r\n",
    "df_trigram['Trigrams_count'] = df_trigram['Trigrams_count'].astype('int8')\r\n",
    "df_trigram.to_csv(\"output/Trigrams.csv\",index=False, sep=';', encoding='utf-8')\r\n",
    "df_trigram.head()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrams_tuple</th>\n",
       "      <th>Trigrams_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(get, help, valeria)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(help, valeria, vasquez)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(valeria, vasquez, amoung)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(vasquez, amoung, fast)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(amoung, fast, efficent)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>(good, customer, service)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>(customer, service, experience)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>(seriously, good, customer)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>(helpful, friendly, thank)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>(perfecto, solucionado, rapidamente)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39149 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Trigrams_tuple  Trigrams_count\n",
       "0                     (get, help, valeria)             1.0\n",
       "0                 (help, valeria, vasquez)             1.0\n",
       "0               (valeria, vasquez, amoung)             1.0\n",
       "0                  (vasquez, amoung, fast)             1.0\n",
       "0                 (amoung, fast, efficent)             1.0\n",
       "...                                    ...             ...\n",
       "5300             (good, customer, service)             1.0\n",
       "5300       (customer, service, experience)             1.0\n",
       "5300           (seriously, good, customer)             1.0\n",
       "5301            (helpful, friendly, thank)             1.0\n",
       "5302  (perfecto, solucionado, rapidamente)             1.0\n",
       "\n",
       "[39149 rows x 2 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Trigrams_count</th>\n",
       "      <th>trigram_1</th>\n",
       "      <th>trigram_2</th>\n",
       "      <th>trigram_3</th>\n",
       "      <th>Trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>get</td>\n",
       "      <td>help</td>\n",
       "      <td>valeria</td>\n",
       "      <td>get help valeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>help</td>\n",
       "      <td>valeria</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>help valeria vasquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>valeria</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>amoung</td>\n",
       "      <td>valeria vasquez amoung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>vasquez</td>\n",
       "      <td>amoung</td>\n",
       "      <td>fast</td>\n",
       "      <td>vasquez amoung fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>1</td>\n",
       "      <td>amoung</td>\n",
       "      <td>fast</td>\n",
       "      <td>efficent</td>\n",
       "      <td>amoung fast efficent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID  Trigrams_count  \\\n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...               1   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...               1   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...               1   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...               1   \n",
       "0  12963500gyg-valeria.vasquezmiranda@teleperform...               1   \n",
       "\n",
       "  trigram_1 trigram_2 trigram_3                Trigrams  \n",
       "0       get      help   valeria        get help valeria  \n",
       "0      help   valeria   vasquez    help valeria vasquez  \n",
       "0   valeria   vasquez    amoung  valeria vasquez amoung  \n",
       "0   vasquez    amoung      fast     vasquez amoung fast  \n",
       "0    amoung      fast  efficent    amoung fast efficent  "
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "######################### Model settings ############################\r\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\r\n",
    "config = AutoConfig.from_pretrained(MODEL)\r\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\r\n",
    "######################################################################\r\n",
    "\r\n",
    "\r\n",
    "########## Preprocess text (username and link placeholders) #########\r\n",
    "def preprocess(text):\r\n",
    "    new_text = []\r\n",
    "    for t in text.split(\" \"):\r\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\n",
    "        t = 'http' if t.startswith('http') else t\r\n",
    "        new_text.append(t)\r\n",
    "    return \" \".join(new_text)\r\n",
    "#####################################################################\r\n",
    "\r\n",
    "\r\n",
    "######################### Use model #################################\r\n",
    "def get_sentiment_scores(tweet):\r\n",
    "    #text = preprocess(tweet)\r\n",
    "    encoded_input = tokenizer(tweet, return_tensors='pt')\r\n",
    "    output = model(**encoded_input)\r\n",
    "    scores = output[0][0].detach().numpy()\r\n",
    "    scores = softmax(scores)\r\n",
    "    return scores\r\n",
    "######################################################################\r\n",
    "\r\n",
    "########################################### Get sentiment #######################################################\r\n",
    "tokenizer.model_max_length = 1028\r\n",
    "lst_negative_scores = []\r\n",
    "lst_neutral_scores = []\r\n",
    "lst_positive_scores = []\r\n",
    "lst_label = []\r\n",
    "\r\n",
    "df_sentiment['Feedback'] = df_sentiment['Feedback'].astype('str')\r\n",
    "df_sentiment=df_sentiment[df_sentiment['Feedback'].str.len() < 1500]\r\n",
    "\r\n",
    "for i in trange(df_sentiment.shape[0]):\r\n",
    "    tweet_i = str(df_sentiment['Feedback'].values[i])\r\n",
    "    \r\n",
    "    scores_array = get_sentiment_scores(tweet_i)\r\n",
    "    negative_score, neutral_score, positive_score = scores_array\r\n",
    "    lst_negative_scores.append(negative_score)\r\n",
    "    lst_neutral_scores.append(neutral_score)\r\n",
    "    lst_positive_scores.append(positive_score)\r\n",
    "    \r\n",
    "    ranking = np.argsort(scores_array)\r\n",
    "    ranking = ranking[::-1]\r\n",
    "    label = config.id2label[ranking[0]]\r\n",
    "    lst_label.append(label)\r\n",
    "    \r\n",
    "df_sentiment['NEGATIVE_SCORE'] = lst_negative_scores\r\n",
    "df_sentiment['NEUTRAL_SCORE'] = lst_neutral_scores\r\n",
    "df_sentiment['POSITIVE_SCORE'] = lst_positive_scores\r\n",
    "df_sentiment['LABEL'] = lst_label\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df_sentiment['NEGATIVE_SCORE'] = df_sentiment['NEGATIVE_SCORE'].astype('str')\r\n",
    "df_sentiment['NEGATIVE_SCORE'] = df_sentiment['NEGATIVE_SCORE'].apply(lambda x: x.replace('.',','))\r\n",
    "\r\n",
    "df_sentiment['NEUTRAL_SCORE'] = df_sentiment['NEUTRAL_SCORE'].astype('str')\r\n",
    "df_sentiment['NEUTRAL_SCORE'] = df_sentiment['NEUTRAL_SCORE'].apply(lambda x: x.replace('.',','))\r\n",
    "\r\n",
    "df_sentiment['POSITIVE_SCORE']=df_sentiment['POSITIVE_SCORE'].astype('str')\r\n",
    "df_sentiment['POSITIVE_SCORE'] = df_sentiment['POSITIVE_SCORE'].apply(lambda x: x.replace('.',','))\r\n",
    "\r\n",
    "df_sentiment.drop(['Feedback','Language'], axis = 1, inplace = True)\r\n",
    "\r\n",
    "df_sentiment.to_csv('output/Sentiment.csv', index=False, sep=';')\r\n",
    "df_sentiment\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b75f8d1de3a34780a2c1d79c55f5278a"
      },
      "text/plain": [
       "  0%|          | 0/5375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>NEUTRAL_SCORE</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12963500gyg-valeria.vasquezmiranda@teleperform...</td>\n",
       "      <td>0,005291904</td>\n",
       "      <td>0,024448082</td>\n",
       "      <td>0,97026</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12990999gyg-fressia.sanchezdelacruz@teleperfor...</td>\n",
       "      <td>0,0043757875</td>\n",
       "      <td>0,011321556</td>\n",
       "      <td>0,9843025</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13002836gyg-karla.chungvelasquez@teleperforman...</td>\n",
       "      <td>0,88507617</td>\n",
       "      <td>0,109285355</td>\n",
       "      <td>0,005638282</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13016161gyg-cinthya.santosmoran@teleperformanc...</td>\n",
       "      <td>0,0722204</td>\n",
       "      <td>0,86461943</td>\n",
       "      <td>0,06316031</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13014113gyg-cinthya.santosmoran@teleperformanc...</td>\n",
       "      <td>0,2217109</td>\n",
       "      <td>0,7468425</td>\n",
       "      <td>0,031446643</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39381</th>\n",
       "      <td>17135621gyg-renato.valdiviasolier@teleperforma...</td>\n",
       "      <td>0,040024474</td>\n",
       "      <td>0,839106</td>\n",
       "      <td>0,12086947</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39383</th>\n",
       "      <td>17616079gyg-alessandra.altamiranopacheco@telep...</td>\n",
       "      <td>0,057740375</td>\n",
       "      <td>0,19127913</td>\n",
       "      <td>0,75098044</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39393</th>\n",
       "      <td>17627457gyg-alondra.chamochumbivicuna@teleperf...</td>\n",
       "      <td>0,0066578286</td>\n",
       "      <td>0,012651858</td>\n",
       "      <td>0,9806903</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>17592259angelo.guerrerolinares@teleperformance...</td>\n",
       "      <td>0,006288374</td>\n",
       "      <td>0,014729161</td>\n",
       "      <td>0,9789824</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39402</th>\n",
       "      <td>17618394gyg-javier.velezmorosanchez@teleperfor...</td>\n",
       "      <td>0,01620404</td>\n",
       "      <td>0,38321462</td>\n",
       "      <td>0,60058135</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5375 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Survey ID NEGATIVE_SCORE  \\\n",
       "6      12963500gyg-valeria.vasquezmiranda@teleperform...    0,005291904   \n",
       "13     12990999gyg-fressia.sanchezdelacruz@teleperfor...   0,0043757875   \n",
       "18     13002836gyg-karla.chungvelasquez@teleperforman...     0,88507617   \n",
       "19     13016161gyg-cinthya.santosmoran@teleperformanc...      0,0722204   \n",
       "25     13014113gyg-cinthya.santosmoran@teleperformanc...      0,2217109   \n",
       "...                                                  ...            ...   \n",
       "39381  17135621gyg-renato.valdiviasolier@teleperforma...    0,040024474   \n",
       "39383  17616079gyg-alessandra.altamiranopacheco@telep...    0,057740375   \n",
       "39393  17627457gyg-alondra.chamochumbivicuna@teleperf...   0,0066578286   \n",
       "39396  17592259angelo.guerrerolinares@teleperformance...    0,006288374   \n",
       "39402  17618394gyg-javier.velezmorosanchez@teleperfor...     0,01620404   \n",
       "\n",
       "      NEUTRAL_SCORE POSITIVE_SCORE     LABEL  \n",
       "6       0,024448082        0,97026  positive  \n",
       "13      0,011321556      0,9843025  positive  \n",
       "18      0,109285355    0,005638282  negative  \n",
       "19       0,86461943     0,06316031   neutral  \n",
       "25        0,7468425    0,031446643   neutral  \n",
       "...             ...            ...       ...  \n",
       "39381      0,839106     0,12086947   neutral  \n",
       "39383    0,19127913     0,75098044  positive  \n",
       "39393   0,012651858      0,9806903  positive  \n",
       "39396   0,014729161      0,9789824  positive  \n",
       "39402    0,38321462     0,60058135  positive  \n",
       "\n",
       "[5375 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "df_agent = df_cat.copy()\r\n",
    "df_brand = df_cat.copy()\r\n",
    "df_channel = df_cat.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def remove_nonalpha(words):\r\n",
    "    list_nonalpha = [w.strip() for w in words if w.strip().isalpha()]        \r\n",
    "    return list_nonalpha \r\n",
    "    \r\n",
    "def get_category(x):\r\n",
    "    key_list = []\r\n",
    "    match_list = []\r\n",
    "    for key in categories_dict.keys():\r\n",
    "        for value in categories_dict[key]:\r\n",
    "            if (bool(re.search(value,x)) ==True):\r\n",
    "                if key not in key_list:\r\n",
    "                    key_list.append(key)\r\n",
    "                    match_list.append(re.compile(value).findall(x))\r\n",
    "    return dict(zip(key_list, match_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\r\n",
    "#Agent \r\n",
    "\r\n",
    "categories_dict = {\r\n",
    "    \"Show Expertise\": [\r\n",
    "        '(agent|rep| he| she|nobody|you|they|still|person|support|helpline)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(didn|wasn|not|no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(know|unexpert|expert)',\r\n",
    "        '(agent|rep| he| she|nobody|you|they|still|person|support|helpline)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(new|hire|rookie)',\r\n",
    "    ], \r\n",
    "    \"Unwilling to Help\": [\r\n",
    "        '(speak|talk|ask|request)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(supervisor|manager)',\r\n",
    "        '(speak|talk|ask|request)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(supervisor|manager)',\r\n",
    "        '(didn|wasn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(pass|let|speak|talk)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(supervisor|manager)',\r\n",
    "        '(didn|wasn|not|no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(supervisor|manager)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(available)'\r\n",
    "    ],\r\n",
    "    \"Impolite\": [\r\n",
    "        '(agent|rep|she|he|be)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(rude|disrespectful|impolite|disrespect|(over talk)|(talk over)|unprofessional|negligent|stubborn|argue|yell)',\r\n",
    "        '(rude|disrespectful|impolite|disrespect|(over talk)|(talk over)|unprofessional|negligent|stubborn)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(agent|rep|she|help|he)',\r\n",
    "        '(no|zero)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(empathy)'\r\n",
    "    ],\r\n",
    "    \"Hang Up\": [\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hang)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)', \r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(finish|end|disconnect|return|drop)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|chat)', \r\n",
    "        '(be)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hang)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)',\r\n",
    "        '(be)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(disconnec|dropped)'   \r\n",
    "    ],\r\n",
    "    \"Knowledgeable\": [\r\n",
    "        '(agent|rep|he|she|nobody|you|they|still|person|support|helpline)(\\s|\\w+\\s|\\s\\w+\\s){0,3}( no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(fast|slow|quick|rapid|rapidly|quickly|speedly )',\r\n",
    "        '(never|didn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|contact|touch|email)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(back)',\r\n",
    "        '(self|myselft|service|selfservice)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(service|myself|option|chance|alternative|resource|possibility)',\r\n",
    "        '(incorrect|miss|incomplete|wrong|inexact|inaccurate|imprecise|erroneous)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(information|detail|fact|data|guidance|instruction|knowledge)',\r\n",
    "        '(still|i|we)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(need)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|solution|answer|resolution|fix)',\r\n",
    "        '(agent|rep|he|she|nobody|you |they|still|person|support|helpline)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(any|zero|no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|resolution|solution|support|assistance)',\r\n",
    "        '(help|solve|fix|address|answer|handle|resolve)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question)',\r\n",
    "        '(no|didn|hasn|wasn|actually)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(get|receive)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(answer|help|resolution|solution|fix)',\r\n",
    "        '(he|she|agent|rep|person)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(didn|not|couldn|wasn|hasn|no|zero)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|answer|help|handle|fix|refund|cancel|clear)',\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(did|do)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(nothing)',\r\n",
    "        '(issue|problem|concern|case|complain|question)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(no|wasn|weren|didn|not|hasn)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|fix|handle|address|answer)',\r\n",
    "        '(didn|wasn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|fix|handle|address|answer)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question)',\r\n",
    "        '(issue|problem|concern|case|complain)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(unresolve|unfix|unhandle)',\r\n",
    "        '(actually)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|solve|fix|address|answer|handle|resolve)',\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(lie)',\r\n",
    "        '(follow)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)',\r\n",
    "        '(never|didn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|contact|touch|email)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(back)',\r\n",
    "        '(never)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(receive|get|return)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|email|chat)'\r\n",
    "    ],\r\n",
    "    \"Issue Resolution\": [\r\n",
    "        '(agent|rep|he|she|nobody|you|they|still|person|support|helpline)(\\s|\\w+\\s|\\s\\w+\\s){0,3}( no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(resolve|handle|address|solve|fix|help|answer|clear )',\r\n",
    "        '(issue|problem|concern|case|complain)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(unresolve|unfix|unhandle)',\r\n",
    "        '(still|i|we)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(need)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|solution|answer|resolution|fix)',\r\n",
    "        '(agent|rep|he|she|nobody|you |they|still|person|support|helpline)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(any|zero|no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|resolution|solution|support|assistance)',\r\n",
    "        '(actually)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|solve|fix|address|answer|handle|resolve)',\r\n",
    "        '(help|solve|fix|address|answer|handle|resolve)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question)',\r\n",
    "        '(no|didn|hasn|wasn|actually)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(get|receive)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(answer|help|resolution|solution|fix)',\r\n",
    "        '(he|she|agent|rep|person)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(didn|not|couldn|wasn|hasn|no|zero)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|answer|help|handle|fix|refund|cancel|clear)',\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(did|do)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(nothing)',\r\n",
    "        '(issue|problem|concern|case|complain|question)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(no|wasn|weren|didn|not|hasn)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|fix|handle|address|answer)',\r\n",
    "        '(didn|wasn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solve|fix|handle|address|answer)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question)',\r\n",
    "        '(didn|wasn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(cancel|refund)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(order|item)',\r\n",
    "        '(issue|problem|concern|case|complain)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(unresolve|unfix|unhandle)',\r\n",
    "        '(actually)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(help|solve|fix|address|answer|handle|resolve)',\r\n",
    "        '(speak|talk)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(manager|supervisor)',\r\n",
    "        '(agente|el|ella|rep|ejecutiva)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(resolver|ayudar|responder|solucion|solución|solucin|solucionar|arreglar|atender|asistir|colaborar|asistencia)',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(no|poder|querer|dar|nadie|brindar)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(resolver|ayudar|respuesta|solucion|solución|solucin|arreglar|atender|asistir|asistencia)',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(solucion|solución|solucionar|solucin|ayuda|respuesta|resolver|arreglar)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(nada|problema|inquietud|necesidad)',\r\n",
    "        '(dar)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solucion|solución|solucionar|solucin|ayuda|respuesta|resolver|asistencia|asisitir|colaborar)',\r\n",
    "        '(problema|pregunta|inconveniente)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(no|ningun)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solucion|solución|solucionar|ayuda|respuesta|resolver|arreglar)',\r\n",
    "        '(nada|no|ningun)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(solucion|solución|solucionar|solucin|ayuda|respuesta|resolver|arreglar)'\r\n",
    "    ],\r\n",
    "    \"Communication Skills\": [\r\n",
    "        '(speak|talk|understad|bad|poor|terrible|horrible)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(english|language|clear)',\r\n",
    "        '(hard|difficult|couldn)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(understand)','(hard|heavy)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(accent)',\r\n",
    "        '(language)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(barrier)','(listen|understand|read)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question|message)',\r\n",
    "        '(no)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(good)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(listen)',\r\n",
    "        '(english)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(no |not |wasn)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(language)',\r\n",
    "        '(speak|understad|bad|poor|terrible|horrible|break|comprehend|write|read)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(english|language)',\r\n",
    "        '(hard|difficult|couldn|imposible)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(understand)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(him|her|rep|agent|english|accent|each)',\r\n",
    "        '(hard|heavy|strong|foreign|break|latin|spanish)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(accent)','(hard|difficult|couldn|impossible)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(understand)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(she|he)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(say)',\r\n",
    "        '(language)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(barrier)','(english)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(first|second)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(language)', \r\n",
    "        '(english)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(poor|bad|break|horrible|terrible)',\r\n",
    "         \"(representante, hablar)\",\"(persona, hablar)\",\"(difícil, entender)\",\r\n",
    "        \"(podría, entender)\",\"(entender, pregunta)\",\"(difícil, tiempo)\",\"(conseguir, alguien)\",\r\n",
    "        \"(hablar, inglés)\",\"(preguntar, hablar)\",\"(entender, problema)\",\"(pesado, acento)\",\r\n",
    "        \"(entender, tema)\",\"(fácil, entender)\",\"(difícil, entender)\",\"(entender, acento)\",\r\n",
    "        \"(contratar, gente)\",\"(entender, inglés)\",\"(rep, hablar)\",\"(dificultad, entender)\",\r\n",
    "        \"(entender, representante)\",\"(entender, vrbo)\",\"(tiempo, entender)\",\"(entender, decir)\",\r\n",
    "        \"(señor, habla)\",\"(dificultad, entender)\",\"(señora,hablar)\"         \r\n",
    "    ],\r\n",
    "    \"Soft Skills\": [\r\n",
    "        '(pesimo|pésimo|mal|malo|horrible|nefasto|ineficiente|insuficiente)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(servicio|atencion|soporte|atención)(\\s|\\w+\\s|\\s\\w+\\s){1,3}',\r\n",
    "        '(agente|el|ella|rep|ejecutiva)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(groser|rudoinepto|irrespetuoso|(mal(\\s|\\w+\\s|\\s\\w+\\s){0,3}educado))',\r\n",
    "        '(poco|no|cero)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(profesional)',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(irrespetuoso)',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,5}(empatia|empatico|empatía|empatica)'\r\n",
    "    ],\r\n",
    "    \"Contact Issues\": [\r\n",
    "        '(agent|rep| he| she|nobody|you|they|still|person|support|helpline)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(end |close|hang|hung|disconnect|leave)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(chat|call|interaction|message)',\r\n",
    "        '(long|excesive|much|put)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hold)',\r\n",
    "        '(agent|rep| he| she|nobody| you|they|still|person|support|helpline)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hung|hang)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)',\r\n",
    "        '(wait|queue)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(speak|hold)(\\s|\\w+\\s|\\s\\w+\\s){0,4}(minutes|mins |min )',\r\n",
    "        '(speak|talk|ask|request)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(supervisor|manager)',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(colgar|finalizar|cerrar|acabar|desconectar|sacar)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(llamada|servicio|mensaje|chat|email|comunicacion|comunicación|interaccion|interacción|ticket|caso|conversación|conversacion|atención|atencion)', \r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(desconectar|cortar|cerrar|colgar)(\\s|\\w+\\s|\\s\\w+\\s){1,3}',\r\n",
    "        '(\\s|\\w+\\s|\\s\\w+\\s){1,3}(espera|hold|silencio)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(minutos|rato|tiempo|hora)',\r\n",
    "        '(hablar|comunicar|platicar|conversar|solicitar|querer|pedir|necesitar|negar)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(manager|supervisor|jefe|superior)'\r\n",
    "    ],\r\n",
    "    \r\n",
    "    \"Understand Customer\": [\r\n",
    "        '(listen|understand|read)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(issue|problem|concern|case|complain|question|message|information)',\r\n",
    "        '(not|wasn)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(good)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(listen)',\r\n",
    "        '(repeat)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(myself)'\r\n",
    "    ],\r\n",
    "    \r\n",
    "    \"RCR\": [\r\n",
    "        '(never)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(receive|get|return)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|email|chat)',\r\n",
    "        '(never|didn|not)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|contact|touch|email)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(back)',\r\n",
    "        '(be|he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(tell)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(get|receive)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|email)',\r\n",
    "        '(be|he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(tell)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(order)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(would|cancel|refund|deliver|ready|receive|send|be|pick)',\r\n",
    "        '(be|he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(tell)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(cancel|refund|get|receive)',\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hang)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)', \r\n",
    "        '( he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(finish|end|disconnect|return)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(call|chat)', \r\n",
    "        '(be)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hang)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)',\r\n",
    "        '(be)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(disconnec)','(hold)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(minutes)',\r\n",
    "        '(follow)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(up)',\r\n",
    "        '(he|she|agent|rep)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(lie)'\r\n",
    "    ],\r\n",
    "\r\n",
    "    \"Unprofessional\": [\r\n",
    "        '(agent|rep|she|he|be)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(rude|disrespectful|impolite|disrespect|(over talk)|(talk over)|unprofessional|negligent|stubborn|argue|yell)',\r\n",
    "        '(rude|disrespectful|impolite|disrespect|(over talk)|(talk over)|unprofessional|negligent|stubborn)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(agent|rep|she|help|he)',\r\n",
    "        '(no|zero)(\\s|\\w+\\s|\\s\\w+\\s){0,5}(empathy)'\r\n",
    "    ]    \r\n",
    "} \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "df_agent['cat_agent_dict'] = df_agent[\"joint_lemma_words\"].apply(lambda x:get_category(x))\r\n",
    "\r\n",
    "df_agent[\"dict_len\"] = df_agent[\"cat_agent_dict\"].apply(lambda x: len(x))\r\n",
    "df_nohits1= df_agent[df_agent[\"dict_len\"] == 0]\r\n",
    "df_agent = df_agent[df_agent[\"dict_len\"] > 0]\r\n",
    "\r\n",
    "df_agent.reset_index(inplace = True, drop=True)\r\n",
    "\r\n",
    "# Melt frequency distribution dictionary\r\n",
    "# https://stackoverflow.com/questions/61354434/melt-pandas-dataframe-containing-column-of-dictionaries-such-that-the-dictionary\r\n",
    "#df_temp_cat_agent = \r\n",
    "df_agent_temp = pd.DataFrame(pd.DataFrame(df_agent['cat_agent_dict'].values.tolist()).stack().reset_index(level=1))\r\n",
    "#df_temp_bigrams.columns = ['Bigrams', 'bigrams_count']\r\n",
    "\r\n",
    "df_agent_temp.columns = ['category', 'hit']\r\n",
    "#df_temp_bigrams\r\n",
    "\r\n",
    "df_agent_temp['hit'] = df_agent_temp['hit'].apply(lambda x: remove_nonalpha(list(x[0])))\r\n",
    "\r\n",
    "# Split trigram tuple in columns\r\n",
    "# https://stackoverflow.com/questions/29550414/how-can-i-split-a-column-of-tuples-in-a-pandas-dataframe\r\n",
    "df_agent_temp = pd.concat([df_agent_temp, pd.DataFrame(df_agent_temp['hit'].tolist(), index=df_agent_temp.index)], axis=1)\r\n",
    "df_agent_temp['hit'] = df_agent_temp['hit'].apply(lambda x : ' '.join(x))\r\n",
    "\r\n",
    "df_agent = df_agent.join(df_agent_temp)\r\n",
    "\r\n",
    "df_agent.drop(['cat_agent_dict', 'dict_len'], axis = 1, inplace = True)\r\n",
    "df_agent['categorization_level'] = 'Agent'\r\n",
    "df_agent.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>joint_lemma_words</th>\n",
       "      <th>category</th>\n",
       "      <th>hit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>categorization_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13028877gyg-wileska.toledocamacaro@teleperform...</td>\n",
       "      <td>speak staff helpful unfortunately activity pro...</td>\n",
       "      <td>Impolite</td>\n",
       "      <td>be city unprofessional</td>\n",
       "      <td>be</td>\n",
       "      <td>city</td>\n",
       "      <td>unprofessional</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13028877gyg-wileska.toledocamacaro@teleperform...</td>\n",
       "      <td>speak staff helpful unfortunately activity pro...</td>\n",
       "      <td>Unprofessional</td>\n",
       "      <td>be city unprofessional</td>\n",
       "      <td>be</td>\n",
       "      <td>city</td>\n",
       "      <td>unprofessional</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12642167gyg-snider.ochoadelgado@teleperformanc...</td>\n",
       "      <td>absolutely terrific help able rearrange new sc...</td>\n",
       "      <td>Show Expertise</td>\n",
       "      <td>he rearrange new</td>\n",
       "      <td>he</td>\n",
       "      <td>rearrange</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13040881gyg-snider.ochoadelgado@teleperformanc...</td>\n",
       "      <td>amazing customer service quick answer solve is...</td>\n",
       "      <td>Knowledgeable</td>\n",
       "      <td>answer solve issue</td>\n",
       "      <td>answer</td>\n",
       "      <td>solve</td>\n",
       "      <td>issue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13040881gyg-snider.ochoadelgado@teleperformanc...</td>\n",
       "      <td>amazing customer service quick answer solve is...</td>\n",
       "      <td>Issue Resolution</td>\n",
       "      <td>answer solve issue</td>\n",
       "      <td>answer</td>\n",
       "      <td>solve</td>\n",
       "      <td>issue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID  \\\n",
       "0  13028877gyg-wileska.toledocamacaro@teleperform...   \n",
       "0  13028877gyg-wileska.toledocamacaro@teleperform...   \n",
       "1  12642167gyg-snider.ochoadelgado@teleperformanc...   \n",
       "2  13040881gyg-snider.ochoadelgado@teleperformanc...   \n",
       "2  13040881gyg-snider.ochoadelgado@teleperformanc...   \n",
       "\n",
       "                                   joint_lemma_words          category  \\\n",
       "0  speak staff helpful unfortunately activity pro...          Impolite   \n",
       "0  speak staff helpful unfortunately activity pro...    Unprofessional   \n",
       "1  absolutely terrific help able rearrange new sc...    Show Expertise   \n",
       "2  amazing customer service quick answer solve is...     Knowledgeable   \n",
       "2  amazing customer service quick answer solve is...  Issue Resolution   \n",
       "\n",
       "                      hit       0          1               2     3     4  \\\n",
       "0  be city unprofessional      be       city  unprofessional  None  None   \n",
       "0  be city unprofessional      be       city  unprofessional  None  None   \n",
       "1        he rearrange new      he  rearrange             new  None  None   \n",
       "2      answer solve issue  answer      solve           issue  None  None   \n",
       "2      answer solve issue  answer      solve           issue  None  None   \n",
       "\n",
       "  categorization_level  \n",
       "0                Agent  \n",
       "0                Agent  \n",
       "1                Agent  \n",
       "2                Agent  \n",
       "2                Agent  "
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Brand\r\n",
    "\r\n",
    "categories_dict = {\r\n",
    "    \"Phone Connectivity\": [\r\n",
    "        '(lantency|intermittence)(\\s|\\w+\\s|\\s\\w+\\s){0,3}( no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hear|listen)',\r\n",
    "        '( no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(hear|listen)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(lantency|intermittence)'\r\n",
    "    ],\r\n",
    "    \"Order Status Check\": [\r\n",
    "        '(deliver|courier|driver)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(long|extended|last|prolonged|time)'\r\n",
    "    ],\r\n",
    "    \"Website experience\": [\r\n",
    "        '(website|link|webpage|page)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(complex|hard|confuse|weird|difficult)', \r\n",
    "        '(website|link|webpage|page)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(crash|error|fail|damage)', \r\n",
    "        '(like|dislike|hate)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(website|link|webpage|page)'   \r\n",
    "    ],\r\n",
    "    \"IVR\": [\r\n",
    "        '(wait|take|stand|hold|stay)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(long|extended|last|prolonged|time)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(he|she|agent|rep)', \r\n",
    "        '(no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(reach|talk|speak)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(he|she|agent|rep)'\r\n",
    "        '(no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(select|find|hear|realize|look|see)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(option|route|chance)',\r\n",
    "        '(complex|hard|confuse|weird|difficult)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(understand|hear|use)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(ivr)',\r\n",
    "        '(take|wait|stand)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(long|extended|last|prolonged|time)',\r\n",
    "        '(long|extended|last|prolonged|time)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(estimate|expect|thing|show)',\r\n",
    "    ],\r\n",
    "    \"Process\": [\r\n",
    "        '(get|earn|give|issue|pay)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(credit|fee|compensation)',\r\n",
    "        '(authenticate|verify|access|confirm|corroborate)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(information|identification|birth|licence|code)',\r\n",
    "        '(no|didn|haven|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(receive|see|look|have)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(payment|money|fee|cash)',\r\n",
    "        '(no|didn|hasn|wasn| can|(could(\\s|\\w+\\s|\\s\\w+\\s){0,3}no))(\\s|\\w+\\s|\\s\\w+\\s){0,3}(use|turn|utilize)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(cellphone|device|phone)',\r\n",
    "        '(cellphone|device|phone)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(5g|network|net|wifi)',\r\n",
    "        '(activate|turn|operate|start)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(cellphone|device|phone)'\r\n",
    "    ],\r\n",
    "    \"Escalation Time\": [\r\n",
    "        '(take|wait|stand|long)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(time|long)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(escalate|transfer)',  \r\n",
    "    ],\r\n",
    "    \"Double Charge\": [\r\n",
    "        '(charge|pay|discount|payment)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(twice|double)'\r\n",
    "    ],\r\n",
    "    \"Refund\": [\r\n",
    "        '(refund|compensation|fee|payment)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(wait|long|take|time|last|now)', \r\n",
    "        '(wait|long|take|time|last|now)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(refund|compensation|fee|payment)',\r\n",
    "        '(give|get|receive)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(refund|compensation|fee|payment)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(now)'\r\n",
    "    ], \r\n",
    "    \"Tour Issues\": [\r\n",
    "        '(tour)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(terrible|aweful|bad|wrong|issues|improve)',\r\n",
    "        '(new|register|just)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(never|tour)'\r\n",
    "    ],\r\n",
    "} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "df_channel['cat_agent_dict'] = df_channel[\"joint_lemma_words\"].apply(lambda x: get_category(x))\r\n",
    "\r\n",
    "df_channel[\"dict_len\"] = df_channel[\"cat_agent_dict\"].apply(lambda x: len(x))\r\n",
    "df_nohits2= df_channel[df_channel[\"dict_len\"] == 0]\r\n",
    "df_channel = df_channel[df_channel[\"dict_len\"] > 0]\r\n",
    "df_channel.reset_index(inplace = True, drop=True)\r\n",
    "\r\n",
    "# Melt frequency distribution dictionary\r\n",
    "# https://stackoverflow.com/questions/61354434/melt-pandas-dataframe-containing-column-of-dictionaries-such-that-the-dictionary\r\n",
    "#df_temp_cat_agent = \r\n",
    "df_channel_temp = pd.DataFrame(pd.DataFrame(df_channel['cat_agent_dict'].values.tolist()).stack().reset_index(level=1))\r\n",
    "#df_temp_bigrams.columns = ['Bigrams', 'bigrams_count']\r\n",
    "\r\n",
    "df_channel_temp.columns = ['category', 'hit']\r\n",
    "#df_temp_bigrams\r\n",
    "\r\n",
    "df_channel_temp['hit'] = df_channel_temp['hit'].apply(lambda x: remove_nonalpha(list(x[0])))\r\n",
    "\r\n",
    "# Split trigram tuple in columns\r\n",
    "# https://stackoverflow.com/questions/29550414/how-can-i-split-a-column-of-tuples-in-a-pandas-dataframe\r\n",
    "df_channel_temp = pd.concat([df_channel_temp, pd.DataFrame(df_channel_temp['hit'].tolist(), index=df_channel_temp.index)], axis=1)\r\n",
    "df_channel_temp['hit'] = df_channel_temp['hit'].apply(lambda x : ' '.join(x))\r\n",
    "\r\n",
    "df_channel = df_channel.join(df_channel_temp)\r\n",
    "\r\n",
    "df_channel.drop(['cat_agent_dict', 'dict_len'], axis = 1, inplace = True)\r\n",
    "df_channel['categorization_level'] = 'Brand'\r\n",
    "df_channel.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>joint_lemma_words</th>\n",
       "      <th>category</th>\n",
       "      <th>hit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>categorization_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13002836gyg-karla.chungvelasquez@teleperforman...</td>\n",
       "      <td>understand charge twice booking accidentally a...</td>\n",
       "      <td>Double Charge</td>\n",
       "      <td>charge twice</td>\n",
       "      <td>charge</td>\n",
       "      <td>twice</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13002836gyg-karla.chungvelasquez@teleperforman...</td>\n",
       "      <td>understand charge twice booking accidentally a...</td>\n",
       "      <td>Refund</td>\n",
       "      <td>take account fee</td>\n",
       "      <td>take</td>\n",
       "      <td>account</td>\n",
       "      <td>fee</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13046780gyg-wileska.toledocamacaro@teleperform...</td>\n",
       "      <td>request refund ask cancel booking operate need...</td>\n",
       "      <td>Refund</td>\n",
       "      <td>wait refund</td>\n",
       "      <td>wait</td>\n",
       "      <td>refund</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12674499gyg-carmen.canalesore@teleperformance....</td>\n",
       "      <td>wait return discuss request refund ghost tour ...</td>\n",
       "      <td>Refund</td>\n",
       "      <td>wait request refund</td>\n",
       "      <td>wait</td>\n",
       "      <td>request</td>\n",
       "      <td>refund</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13065430gyg-grecia.romanneyra@teleperformance....</td>\n",
       "      <td>wait period pretty long matter need meet resolve</td>\n",
       "      <td>IVR</td>\n",
       "      <td>wait pretty long</td>\n",
       "      <td>wait</td>\n",
       "      <td>pretty</td>\n",
       "      <td>long</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID  \\\n",
       "0  13002836gyg-karla.chungvelasquez@teleperforman...   \n",
       "0  13002836gyg-karla.chungvelasquez@teleperforman...   \n",
       "1  13046780gyg-wileska.toledocamacaro@teleperform...   \n",
       "2  12674499gyg-carmen.canalesore@teleperformance....   \n",
       "3  13065430gyg-grecia.romanneyra@teleperformance....   \n",
       "\n",
       "                                   joint_lemma_words       category  \\\n",
       "0  understand charge twice booking accidentally a...  Double Charge   \n",
       "0  understand charge twice booking accidentally a...         Refund   \n",
       "1  request refund ask cancel booking operate need...         Refund   \n",
       "2  wait return discuss request refund ghost tour ...         Refund   \n",
       "3   wait period pretty long matter need meet resolve            IVR   \n",
       "\n",
       "                   hit       0        1       2     3     4  \\\n",
       "0         charge twice  charge    twice    None  None  None   \n",
       "0     take account fee    take  account     fee  None  None   \n",
       "1          wait refund    wait   refund    None  None  None   \n",
       "2  wait request refund    wait  request  refund  None  None   \n",
       "3     wait pretty long    wait   pretty    long  None  None   \n",
       "\n",
       "  categorization_level  \n",
       "0                Brand  \n",
       "0                Brand  \n",
       "1                Brand  \n",
       "2                Brand  \n",
       "3                Brand  "
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "df = pd.concat([df_agent, df_channel])\r\n",
    "df.drop(['joint_lemma_words',0,1,2,3,4], axis = 1, inplace = True)\r\n",
    "df.categorization_level.value_counts(dropna=False)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Agent    1065\n",
       "Brand     189\n",
       "Name: categorization_level, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "df_sentiment=pd.read_csv('output/Sentiment.csv', sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df = df.merge(df_sentiment, on='Survey ID')\r\n",
    "df.to_csv('output/Categorization.csv', index=False, sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Detractors Categorization"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "df2_csat = data.loc[:, ['Survey ID', 'CSAT']]\r\n",
    "merged_df = pd.merge(df_cat, df2_csat, on='Survey ID', how='left')\r\n",
    "df_detractor=merged_df[(merged_df['CSAT']=='Passive') | (merged_df['CSAT']=='Detractor')]\r\n",
    "df_promoter=merged_df[merged_df['CSAT']=='Promoter']\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "categories_dict = {\r\n",
    "    \"Clarity\" : [\r\n",
    "        '(clear|unclear|cl.ar|cle.r|uncl.ar|uncle.r)(\\s+\\w+){0,3}(service|ask|intelligent|answer|response|information)',\r\n",
    "        '((clear|unclear|cl.ar|cle.r|uncl.ar|uncle.r)\\s+)?(service(\\s+\\w+)?|\\w+(\\s+\\w+)?\\s+unclear)',\r\n",
    "        'hard|complicated|impossible(\\s+\\w+){0,3}\\s+understand',\r\n",
    "        'clearly(\\s+\\w+){0,3}chat|person?(\\s+\\w+){0,3}chat|person?',\r\n",
    "        '(lack|bad|wrong|could)?(\\s+\\w+){0,3}(understanding|understand)(\\s+\\w+){0,3}(english)?(\\s+\\w+){0,3}(language)?',\r\n",
    "        '(no\\s+entiendo|difícil\\s+de\\s+entender|poco\\s+claro)(\\s+\\w+){0,3}(información|respuesta|servicio|ayuda)',\r\n",
    "        '(confuso|confundido|incomprensible|oscuro)(\\s+\\w+){0,3}(información|respuesta|servicio|ayuda)',\r\n",
    "        'ayuda(\\s+\\w+){0,3}(confusa|confundida|poco\\s+clara)',\r\n",
    "        '(respuesta|información|ayuda|servicio)(\\s+\\w+){0,3}(ambigua|ambiguo|vaga|vago)',\r\n",
    "        '(respuesta|información|ayuda|servicio)(\\s+\\w+){0,3}(incompleta|incompleto)',\r\n",
    "        '(respuesta|información|ayuda|servicio)(\\s+\\w+){0,3}(incorrecta|incorrecto)',\r\n",
    "        'ambiguo|vago(\\s+\\w+){0,3}(respuesta|información|ayuda|servicio)',\r\n",
    "        'incompleto(\\s+\\w+){0,3}(respuesta|información|ayuda|servicio)',\r\n",
    "        'incorrecto(\\s+\\w+){0,3}(respuesta|información|ayuda|servicio)'\r\n",
    "],\r\n",
    "    \"Problem Solving\":[\r\n",
    "        '(poor|waste|bad)(\\s\\w+){0,3}(service)', \r\n",
    "        '(time)(\\s\\w+){0,3}(waste)',  \r\n",
    "        '(resolve|fix|help|assist)(\\s\\w+){0,3}(problem)', \r\n",
    "        '(unable)(\\s\\w+){0,3}(help)', 'cause(\\s\\w+){0,3}trouble',  \r\n",
    "        '(issue|problem)(\\s\\w+){0,3}(not(\\s\\w+){0,3}solved|unsolved|unresolved|unfixed|unresolved)',   \r\n",
    "        '(solving|unsolving|unresolving|not(\\s\\w+){0,3}fixing|unfixing)(\\s\\w+){0,3}(problem|issue)',\r\n",
    "        '(problem|issue)(\\s\\w+){0,3}(ignored|neglected|unattended|unaddressed)',  \r\n",
    "        '(useless|worthless|ineffective|unhelpful|unproductive)(\\s\\w+){0,3}(help|assistance)',  \r\n",
    "        '(did(\\s\\w+){0,3}nothing|nothing(\\s\\w+){0,3}(done|accomplished)|no(\\s\\w+){0,3}action(\\s\\w+){0,3}taken)',\r\n",
    "        '(support|service)(\\s\\w+){0,3}(not(\\s\\w+){0,3}working|broken|useless|ineffective)', \r\n",
    "        '(able)?(\\s\\w+){0,3}(solve|fix|help|assist)(\\s\\w+){0,3}(issue|problem)',\r\n",
    "        '(help|assist|solve|fix|resolve)(\\s\\w+){0,3}(problem|issue)',\r\n",
    "        '(useless|worthless|ineffective|unhelpful|unproductive)(\\s\\w+){0,3}(support|service)',\r\n",
    "         '(servicio\\s)?(pobre|malo|deficiente|insuficiente|ineficaz)',\r\n",
    "        'tiempo(\\s\\w+){0,3}(perdido|desperdiciado)',\r\n",
    "        '(solucionar|arreglar|ayudar|asistir)(\\s\\w+){0,3}(problema)',\r\n",
    "        '(no\\s)?(capaz|poder)(\\s\\w+){0,3}(ayudar|solucionar)',\r\n",
    "        'caus(\\s\\w+){0,3}(problemas|inconvenientes)',\r\n",
    "        'respuestas(\\s\\w+){0,3}(lentas|tardadas)',\r\n",
    "        'atención(\\s\\w+){0,3}(deficiente|pobre|insuficiente|ineficaz)',\r\n",
    "        '(mala|pobre|deficiente|insuficiente|ineficaz)(\\s\\w+){0,3}(comunicación|respuesta)',\r\n",
    "        '(no\\s)?(resolver|solucionar|arreglar)(\\s\\w+){0,3}(solicitud|problema)',\r\n",
    "        '(no\\s)?(ayudar|asistir|brindar)(\\s\\w+){0,3}(solución|respuesta)'\r\n",
    "        \r\n",
    "    ],\r\n",
    "    \"Knowledge\":[\r\n",
    "        '(incorrect|wrong|bad|false)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(information|problem)',\r\n",
    "        '(completely)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(false|accurate)',\r\n",
    "        '\\b(lie)\\b',\r\n",
    "        '(incorrecta|equivocada|falsa)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(información|dato|problema)',\r\n",
    "        '(completamente)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(falso|preciso)',\r\n",
    "        '\\b(mentira)\\b',\r\n",
    "        '(saber)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(respuesta)',\r\n",
    "        '(información incorrecta|dato incorrecto|información errónea)',\r\n",
    "        '(información equivocada|dato equivocado|información incorrecta)',\r\n",
    "        '(datos incorrectos|datos erróneos)',\r\n",
    "        '(mala información|mala respuesta)',\r\n",
    "        r'(incorrect|wrong|bad|false)?(\\s|\\w+\\s|\\s\\w+\\s){0,3}(information|problem)',\r\n",
    "        r'(completely)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(false|accurate)',\r\n",
    "        r'(lie)',\r\n",
    "        r'(know)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(nothing|answer)',\r\n",
    "        r'(incorrect|wrong)(\\s|\\w+\\s|\\s\\w+\\s){0,3}(information|info)',\r\n",
    "    ],\r\n",
    "    \"Responsiveness\" : [\r\n",
    "        '(long|forever|too(\\s\\w+){0,3}long|lengthy)(\\s\\w+){0,3}(wait|hold|response)',\r\n",
    "        '(disconnected|disconnection|drop|dropped)(\\s\\w+){0,3}(chat|call)',\r\n",
    "        'hang(\\s\\w+){0,3}(up|on)?',\r\n",
    "        'took(\\s\\w+){0,3}(forever|too(\\s\\w+){0,3}long)',\r\n",
    "        '(waiting(\\s\\w+){0,3}time|time(\\s\\w+){0,3}(wait|hold|response))(\\s\\w+){0,3}(long|forever|too(\\s\\w+){0,3}long|lengthy)',\r\n",
    "        '(service(\\s\\w+){0,3}(delayed|taking(\\s\\w+){0,3}long)|response(\\s\\w+){0,3}(time|delay))(\\s\\w+){0,3}(long|forever|too(\\s\\w+){0,3}long|lengthy)',\r\n",
    "        \"long(\\s\\w+){0,3}wait\",\r\n",
    "        \"too(\\s\\w+){0,3}long(\\s\\w+){0,3}(chat|response|time)\",\r\n",
    "        \"waited(\\s\\w+){0,3}(hours|minutes|time)(\\s\\w+){0,3}(hold|on hold|for a response)\",\r\n",
    "        \"disconnected(\\s\\w+){0,3}chat\",\r\n",
    "        \"hung(\\s\\w+){0,3}up(\\s\\w+){0,3}(chat|conversation)\",\r\n",
    "        \"ignored(\\s\\w+){0,3}(chat|conversation|message)\",\r\n",
    "        \"(chat|response)(\\s\\w+){0,3}(delayed|slow|taking(\\s\\w+){0,3}forever|not(\\s\\w+){0,3}responding)\",\r\n",
    "        \"(response|chat)(\\s\\w+){0,3}(time|speed)(\\s\\w+){0,3}(too(\\s\\w+){0,3}slow|unacceptable|poor|bad)\",\r\n",
    "        '(espera(\\s+\\w+){0,3}(larga|demasiado(\\s+\\w+){0,3}larga|interminable)|tiempo(\\s+\\w+){0,3}(de\\s+espera|de\\s+respuesta)(\\s+\\w+){0,3}(largo|demasiado(\\s+\\w+){0,3}largo|interminable))',\r\n",
    "        '(desconectado|desconexión|caída|caído)(\\s+\\w+){0,3}(chat|llamada|conexión)',\r\n",
    "        'colg(ó|ando)(\\s+\\w+){0,3}(el\\s+teléfono|en\\s+el\\s+chat)?',\r\n",
    "        'tard(ó|ando)(\\s+\\w+){0,3}(demasiado|una\\s+eternidad)',\r\n",
    "        '(demora|retraso)(\\s+\\w+){0,3}(en\\s+el\\s+servicio|en\\s+la\\s+respuesta|en\\s+responder|en\\s+contestar)',\r\n",
    "        '(tiempo(\\s+\\w+){0,3}espera)'\r\n",
    "    ],\r\n",
    "\r\n",
    "    \r\n",
    "    'Friendliness': [\r\n",
    "       '(friendly(\\s+\\w+){0,1}\\s+lack|lack(\\s+\\w+){0,1}\\s+friendly)',\r\n",
    "        '\\b(rude)\\b.*?\\b(customer service|agent|representative|support)\\b',\r\n",
    "        \"friendly(\\\\s+\\\\w+){0,1}\\\\s+lack|lack(\\\\s+\\\\w+){0,1}\\\\s+friendly\",\r\n",
    "        \"\\\\b(rude)\\\\b.*?\\\\b(agent|person|rep|representative|support)\\\\b\",\r\n",
    "        \"(un)?(empathetic|empathy|empathize)(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        \"(condescending|patronizing)(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        \"took(\\\\s+\\\\w+){0,3}(seriously|serious)(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        \"over(?:-|\\\\s)?talk(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        \"apologize(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        \"(polite|courteous|respectful)(\\\\s+\\\\w+){0,3}(agent|person|rep|representative|support)?\",\r\n",
    "        '(falta(\\s+\\w+){0,1}\\s+de(\\s+\\w+){0,1}\\s+amabilidad|amabilidad(\\s+\\w+){0,1}\\s+falta)',\r\n",
    "        '\\b(mal|groser|descortés)\\b.?\\b(servicio al cliente|agente|representante|soporte)\\b',\r\n",
    "        \"amabilidad(\\s+\\w+){0,1}\\s+falta|falta(\\s+\\w+){0,1}\\s+amabilidad\",\r\n",
    "        \"\\b(mal|groser|descortés)\\b.?\\b(agente|persona|representante|soporte)\\b\",\r\n",
    "        \"(falta de )?(empatía|empático|empatizar)(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\",\r\n",
    "        \"(condescendiente|paternalista)(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\",\r\n",
    "        \"no tom(ó|aron)(\\s+\\w+){0,3}(en serio|en cuenta)(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\",\r\n",
    "        \"(interrumpir|hablar de más|no dejar hablar)(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\",\r\n",
    "        \"disculparse(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\",\r\n",
    "        \"(político|cortés|respetuoso)(\\s+\\w+){0,3}(agente|persona|representante|soporte)?\"\r\n",
    "    ],\r\n",
    "    'Professionalism':\r\n",
    "    [\r\n",
    "        r'\\b(unprofessional|unethical|unacceptable|inappropriate)\\b.*?\\b(service|behavior|conduct|attitude)\\b',\r\n",
    "        r'\\b(service|behavior|conduct|attitude)\\b.*?\\b(unprofessional|unethical|unacceptable|inappropriate)\\b',\r\n",
    "        r'\\b(agent|representative|support)\\b.*?\\b(professional|polite|courteous|respectful|helpful)\\b',\r\n",
    "        r'\\b(professional|polite|courteous|respectful|helpful)\\b.*?\\b(agent|representative|support)\\b',\r\n",
    "        r'(?i)\\b(emoji|emoticon)\\b.*?\\b(unprofessional|inappropriate|misinterpreted|misused)\\b',\r\n",
    "        r'(?i)\\b(unprofessional|inappropriate|misinterpreted|misused)\\b.*?\\b(emoji|emoticon)\\b',\r\n",
    "        r'\\b(agente|representante|soporte)\\b.*?\\b(profesional|educado|cortés|respetuoso|servicial)\\b',\r\n",
    "        r'\\b(profesional|educado|cortés|respetuoso|servicial)\\b.*?\\b(agente|representante|soporte)\\b',\r\n",
    "        r'(?i)\\b(emoji|emoticono)\\b.*?\\b(poco profesional|inapropiado|malinterpretado|mal utilizado)\\b',\r\n",
    "        r'(?i)\\b(poco profesional|inapropiado|malinterpretado|mal utilizado)\\b.*?\\b(emoji|emoticono)\\b'\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "df_detractor['cat_dict'] = df_detractor['joint_lemma_words'].apply(lambda x:get_category(str(x)))\r\n",
    "\r\n",
    "\r\n",
    "df_detractor['dict_len'] = df_detractor['cat_dict'].apply(lambda x: len(x))\r\n",
    "df_detractor=df_detractor[df_detractor['dict_len']>0]\r\n",
    "df_detractor.drop('dict_len', axis=1, inplace=True)\r\n",
    "df_detractor.reset_index(inplace=True, drop=True)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df_detractor_temp = pd.DataFrame(pd.DataFrame(df_detractor['cat_dict'].values.tolist()).stack().reset_index(level=1))\r\n",
    "df_detractor_temp.columns = ['category', 'hit']\r\n",
    "#df_temp_bigrams\r\n",
    "\r\n",
    "df_detractor_temp['hit'] = df_detractor_temp['hit'].apply(lambda x: remove_nonalpha(list(x[0])))\r\n",
    "\r\n",
    "# Split trigram tuple in columns\r\n",
    "# https://stackoverflow.com/questions/29550414/how-can-i-split-a-column-of-tuples-in-a-pandas-dataframe\r\n",
    "df_detractor_temp = pd.concat([df_detractor_temp, pd.DataFrame(df_detractor_temp['hit'].tolist(), index=df_detractor_temp.index)], axis=1)\r\n",
    "df_detractor_temp['hit'] = df_detractor_temp['hit'].apply(lambda x : ' '.join(x))\r\n",
    "\r\n",
    "df_detractor = df_detractor.join(df_detractor_temp)\r\n",
    "\r\n",
    "df_detractor.drop(['cat_dict'], axis = 1, inplace = True)\r\n",
    "df_detractor['categorization_level'] = 'Dissatisfier'\r\n",
    "df_detractor.drop('joint_lemma_words', inplace=True, axis=1)\r\n",
    "df_detractor.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>CSAT</th>\n",
       "      <th>category</th>\n",
       "      <th>hit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>categorization_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13002836gyg-karla.chungvelasquez@teleperforman...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Clarity</td>\n",
       "      <td>understand booking cancel</td>\n",
       "      <td>understand</td>\n",
       "      <td>booking</td>\n",
       "      <td>cancel</td>\n",
       "      <td>Dissatisfier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12977594gyg-grecia.romanneyra@teleperformance....</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Clarity</td>\n",
       "      <td>request</td>\n",
       "      <td>request</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Dissatisfier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13069495gyg-pablo.amasifuensacsa@teleperforman...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Clarity</td>\n",
       "      <td>understand policy want</td>\n",
       "      <td>understand</td>\n",
       "      <td>policy</td>\n",
       "      <td>want</td>\n",
       "      <td>Dissatisfier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13040466gyg-andre.lopezsenitagoya@teleperforma...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Clarity</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Dissatisfier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13084100gyg-alvaro.floresuribe@teleperformance...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Clarity</td>\n",
       "      <td>sitka</td>\n",
       "      <td>sitka</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Dissatisfier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Survey ID       CSAT category  \\\n",
       "0  13002836gyg-karla.chungvelasquez@teleperforman...  Detractor  Clarity   \n",
       "1  12977594gyg-grecia.romanneyra@teleperformance....  Detractor  Clarity   \n",
       "2  13069495gyg-pablo.amasifuensacsa@teleperforman...  Detractor  Clarity   \n",
       "3  13040466gyg-andre.lopezsenitagoya@teleperforma...  Detractor  Clarity   \n",
       "4  13084100gyg-alvaro.floresuribe@teleperformance...    Passive  Clarity   \n",
       "\n",
       "                         hit           0        1       2 categorization_level  \n",
       "0  understand booking cancel  understand  booking  cancel         Dissatisfier  \n",
       "1                    request     request     None    None         Dissatisfier  \n",
       "2     understand policy want  understand   policy    want         Dissatisfier  \n",
       "3                                   None     None    None         Dissatisfier  \n",
       "4                      sitka       sitka     None    None         Dissatisfier  "
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "df_detractor = df_detractor.merge(df_sentiment, on='Survey ID')\r\n",
    "df_detractor.to_csv('output/DSAT_Categorization.csv', index=False, sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from datetime import datetime as dt \r\n",
    "\r\n",
    "print('Updated on', dt.now())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated on 2023-06-01 09:59:01.259347\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}